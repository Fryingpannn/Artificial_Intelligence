{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exempt-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adverse-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sklearn.datasets.load_files(\"BBC\", encoding=\"latin1\", decode_error='strict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "foreign-magnitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "term_document_matrix = count_vect.fit_transform(dataset.data)\n",
    "x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(term_document_matrix, dataset.target,test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "suburban-fifty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "greek-insertion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9752808988764045"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "predicted = clf.predict(x_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sticky-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(y_test, predicted)\n",
    "report = sklearn.metrics.classification_report(y_test, predicted,target_names=dataset.target_names)\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test, predicted)\n",
    "macro_average = sklearn.metrics.f1_score(y_test, predicted, average=\"macro\")\n",
    "weighted_average = sklearn.metrics.f1_score(y_test, predicted, average=\"weighted\")\n",
    "vocab_size = len(count_vect.get_feature_names())\n",
    "\n",
    "word_token_per_class = {}\n",
    "for category in dataset.target_names:\n",
    "    word_token_per_class[category] = 0\n",
    "zero_per_class = []\n",
    "array = term_document_matrix.toarray()\n",
    "for category_index in range (0, len(dataset.target_names)):\n",
    "    for i in range (0,len(dataset.target)):\n",
    "        zeros = 0\n",
    "        if dataset.target[i] == category_index:\n",
    "            row = array[i]\n",
    "            for j in row:\n",
    "                word_token_per_class[dataset.target_names[category_index]] += j\n",
    "\n",
    "total_words = 0\n",
    "for key, val in word_token_per_class.items():\n",
    "    total_words += val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "appreciated-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bbc-performance.txt', 'w') as f:\n",
    "    f.write(\"(a) ************** Multi-nomialNB default values, try 1\")\n",
    "    f.write('\\n')\n",
    "    f.write(\"(b) confusion matrix:\\n\" )\n",
    "    f.writelines([\"%s\\n\" % item  for item in confusion])\n",
    "    f.write('\\n')\n",
    "    f.write(\"(c) report:\\n\")\n",
    "    f.write(str(report))\n",
    "    f.write('\\n')\n",
    "    f.write(\"(d) accuracy: \"+ str(accuracy) + \"     macro-average F1: \" + str(macro_average) + \"     weighted-average F1: \" + str(weighted_average))\n",
    "    f.write('\\n')\n",
    "    f.write(\"(f) vocabulary size: \"+str(vocab_size))\n",
    "    f.write('\\n')\n",
    "    f.write(\"(g) word token per class\\n\")\n",
    "    for key, val in word_token_per_class.items():\n",
    "        f.write(str(key)+\" : \"+str(val))\n",
    "    f.write('\\n')\n",
    "    f.write(\"(k) Total word count: \" + str(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deadly-original",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha = 0.0001)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "clf = MultinomialNB(alpha = 0.9)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-tomato",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
